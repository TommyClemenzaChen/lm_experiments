{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 08:47:05.205492: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-23 08:47:05.246499: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-23 08:47:06.051341: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0ccb382c714b368dd7dda8834df95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/883 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9efec234ca425a80693e4d2fc383b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7f7ba5321fb471c8577000cdae79983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24efd0e0f17d4a7ea4520fb33f5a30f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9911c4b71f42ecac8bef46289b0f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cf848dbe324175b19a1549d834e46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe = pipeline(\"text-generation\", model=\"NousResearch/Hermes-3-Llama-3.1-8B\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.memory_allocated() / (1024 ** 3), \"GB allocated after loading\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "import json\n",
    "\n",
    "class StudentProfile(BaseModel):\n",
    "    major: str\n",
    "    bio: str\n",
    "\n",
    "def validate_json(response: str):\n",
    "    try:\n",
    "        # Attempt to parse and validate the response as a StudentProfile\n",
    "        student_profile = StudentProfile.parse_raw(response)\n",
    "        return student_profile\n",
    "    except ValidationError as e:\n",
    "        # Catch invalid JSON or schema errors and return None\n",
    "        print(f\"Invalid JSON or structure: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Catch invalid JSON formatting errors\n",
    "        print(f\"JSON Decode Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(messages):\n",
    "    # Generate a response from pipeline \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are tasked with generating a college student profile for the \"{major}\" major in valid JSON format.\n",
    "\n",
    "Requirements:\n",
    "The profile must include the following fields:\n",
    "\"major\": \"{major}\"\n",
    "\"bio\": A detailed description of the student's activities, achievements, projects, leadership positions, internships, research, and goals. The bio must not contain single quotes (') or unescaped special characters.\n",
    "\n",
    "2. Strict Formatting Rules:\n",
    "    \n",
    "All keys and string values \n",
    "must use double quotes (\").\n",
    "    \n",
    "Ensure proper placement of all braces ({{}}, {{}}), commas (,), and other JSON syntax.\n",
    "The output must be a complete and valid JSON object.\n",
    "\n",
    "3. Output Restrictions:\n",
    "    \n",
    "Do not include names, gender, school, or any other personal identifiers.\n",
    "Avoid extra text or commentary outside the JSON object.\n",
    "\n",
    "4. Error Handling:\n",
    "    \n",
    "If valid JSON cannot be generated, return this exact string: \"Invalid JSON\".\n",
    "\n",
    "Example of Valid JSON:\n",
    "{\n",
    "    \"major\": \"{major}\",\n",
    "    \"bio\": \"A detailed description of the student's activities, achievements, projects, leadership positions, internships, research, and goals.\"\n",
    "}\n",
    "\n",
    "Task:\n",
    "Generate a JSON object containing exactly ONE student profile** for the \"{major}\" major. Ensure the JSON is properly formatted and valid. If you cannot generate valid JSON, return \"Invalid JSON\".\n",
    "\"\"\"\n",
    "\n",
    "major = \"Computer Science\"\n",
    "formatted_prompt = prompt_template.format(major=major)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
