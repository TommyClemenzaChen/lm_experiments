{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch ipywidgets flash-attn\n",
    "!pip install -q accelerate>=0.26.0\n",
    "!pip install -U -q bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289c2abeed984d529fbf797a50d9727a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import accelerate\n",
    "import bitsandbytes, flash_attn\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # or load_in_8bit=True\n",
    ")\n",
    "\n",
    "model_name = \"NousResearch/Hermes-3-Llama-3.1-8B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.290787696838379 GB allocated after loading\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.memory_allocated() / (1024 ** 3), \"GB allocated after loading\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "import json\n",
    "\n",
    "class StudentProfile(BaseModel):\n",
    "    major: str\n",
    "    bio: str\n",
    "\n",
    "def validate_json(response: str):\n",
    "    try:\n",
    "        # Attempt to parse and validate the response as a StudentProfile\n",
    "        student_profile = StudentProfile.parse_raw(response)\n",
    "        return student_profile\n",
    "    except ValidationError as e:\n",
    "        # Catch invalid JSON or schema errors and return None\n",
    "        print(f\"Invalid JSON or structure: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Catch invalid JSON formatting errors\n",
    "        print(f\"JSON Decode Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant that answers in JSON. Here's the json schema you must adhere to:\n",
    "<schema>\n",
    "{{\n",
    "    \"major\": \"string\",\n",
    "    \"bio\": \"string\"\n",
    "}}\n",
    "</schema><|im_end|>\n",
    "<|im_start|>user\n",
    "Generate a student profile for {major} major.<|im_end|>\n",
    "<|im_start|>assistant\n",
    "<|im_end|>\"\"\"\n",
    "\n",
    "major = \"Computer Science\"\n",
    "formatted_prompt = chat_template.format(major=major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, prompt, temperature=1.0, num_return_sequences=1, device = \"cuda\"):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "    \n",
    "    # Generate\n",
    "    generated_ids = model.generate(\n",
    "        input_ids,\n",
    "        temperature=temperature, \n",
    "        repetition_penalty=1.1,\n",
    "        num_return_sequences=num_return_sequences,\n",
    "        do_sample=True, \n",
    "        max_length=512,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Decode and return the generated text\n",
    "    response = tokenizer.decode(generated_ids[0][input_ids.shape[-1]:], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
    "\n",
    "    \n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "response = generate_response(model, tokenizer, formatted_prompt, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'major': 'Computer Science',\n",
       " 'bio': 'A passionate and ambitious student with an innate curiosity for technology and problem-solving, specializing in computer science. Skilled in various programming languages, experienced with algorithms and data structures. Enthusiastic about emerging technologies and their potential applications.'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json.loads(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n:// End of response\\n:// -------------------------------------------------\\nphp\\n// Start of user input\\nenter code here\\n{\\n    \"major\": \"Mathematics\",\\n    \"bio\": \"I am an undergraduate studying Mathematics at XYZ University. My primary focus is on discrete mathematics, and I hope to apply my knowledge to develop efficient algorithms.\"\\n}\\n\\n?>'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"major\": \"Computer Science\",\n",
      "  \"bio\": \"A passionate and ambitious student with an innate curiosity for technology and problem-solving. Skilled in Python, Java, and JavaScript, with experience in web development and machine learning algorithms. Actively involved in various coding competitions and hackathons, always seeking opportunities to learn and grow within the dynamic field of computer science.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_json_response(response):\n",
    "    \"\"\"\n",
    "    Extract clean JSON from model response\n",
    "    \n",
    "    Args:\n",
    "        response (str or list): Model response\n",
    "    Returns:\n",
    "        str: Formatted JSON string\n",
    "    \"\"\"\n",
    "    # Convert list to string if necessary\n",
    "    if isinstance(response, list):\n",
    "        response = response[0]\n",
    "    \n",
    "    # Find the JSON object using regex\n",
    "    match = re.search(r'\\{[\\s\\S]*\\}', response)\n",
    "    if match:\n",
    "        try:\n",
    "            # Extract the matched JSON string\n",
    "            json_str = match.group(0)\n",
    "            # Parse and reformat to ensure valid JSON\n",
    "            parsed_json = json.loads(json_str)\n",
    "            # Return formatted JSON\n",
    "            return json.dumps(parsed_json, indent=2)\n",
    "        except json.JSONDecodeError:\n",
    "            return \"Invalid JSON\"\n",
    "    return \"Invalid JSON\"\n",
    "\n",
    "# Example usage:\n",
    "model_response = generate_response(model, tokenizer, formatted_prompt, temperature=0.5) # Your model response\n",
    "clean_json = extract_json_response(model_response)\n",
    "print(clean_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return only a valid JSON object for a college student profile for the \"Computer Science\" major.\n",
      "\n",
      "The JSON must have these fields:\n",
      "- \"major\": \"Computer Science\"\n",
      "- \"bio\": Student's activities, achievements, projects, leadership positions, internships, research, and goals\n",
      "\n",
      "Format rules:\n",
      "- Use double quotes for all keys and values\n",
      "- No text outside the JSON object\n",
      "- No personal identifiers or names\n",
      "- No single quotes or unescaped characters\n",
      "\n",
      "Example format:\n",
      "{\"major\": \"Example Major\", \"bio\": \"Example bio text\"}\n",
      "\n",
      "Generate exactly one profile in valid JSON: \n",
      "\n",
      "{\n",
      "  \"major\": \"Computer Science\",\n",
      "  \"bio\": \"Passionate computer science student with a strong foundation in programming, data structures, and algorithms. Experienced in multiple programming languages including Java, Python, and C++. Actively involved in hackathons and coding competitions, securing multiple top placements. Contributor to open-source projects, focusing on improving code efficiency and scalability. Seeking opportunities to apply my skills in real-world projects and collaborate with like-minded individuals to develop innovative solutions.\"\n",
      "}://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "://\n",
      "<div class=\"post-meta\" style=\"display: none;\">Архів\n",
      "<div class=\"post\" style=\"display: none;\">\n",
      "<div class=\"post-inner\">\n",
      "<div class=\"post-content\">\n",
      "<div class=\"post-header\">\n",
      "<div class=\"post-title\">\n",
      "<h1 itemprop=\"headline\">Computer Science Student Profile</h1>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"post-meta\">\n",
      "<div class=\"post-meta\">\n",
      "<div class=\"post-meta-item\">\n",
      "<span class=\"post-author\">By <span itemprop=\"author\">Alex Smith</span></div>\n",
      "<div class=\"post-meta-item\">\n",
      "<span class=\"post-date\">March 10, 2023</span></div>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "<div class=\"post-content\">\n",
      "<p>Passionate computer science student with a strong foundation in programming, data structures, and algorithms. Experienced in Java, Python, and C++. Involved in hackathons and coding competitions, securing top placements. Contributor to open-source projects, focusing on code efficiency and scalability. Seeking opportunities to apply skills to real-world projects and collaborate on innovative solutions.</p>\n",
      "</div>\n",
      "</div>\n",
      "</div>\n",
      "</div>Архів\n",
      "</div>://\n"
     ]
    }
   ],
   "source": [
    "print(model_response[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
