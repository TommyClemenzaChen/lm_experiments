{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch ipywidgets flash-attn\n",
    "!pip install -q accelerate>=0.26.0\n",
    "!pip install -U -q bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate\n",
    "print(accelerate.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 10:38:41.442324: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-24 10:38:42.631274: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17d7025b7d4f4da482246d1c8ac455d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import torch\n",
    "import accelerate\n",
    "import bitsandbytes, flash_attn\n",
    "\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # or load_in_8bit=True\n",
    ")\n",
    "\n",
    "model_name = \"NousResearch/Hermes-3-Llama-3.1-8B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    torch_dtype=torch.float16, \n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config,\n",
    "    attn_implementation=\"flash_attention_2\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.bnb_4bit_compute_dtype = torch.float16  # Align with `torch_dtype=torch.float16`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.memory_allocated() / (1024 ** 3), \"GB allocated after loading\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, ValidationError\n",
    "import json\n",
    "\n",
    "class StudentProfile(BaseModel):\n",
    "    major: str\n",
    "    bio: str\n",
    "\n",
    "def validate_json(response: str):\n",
    "    try:\n",
    "        # Attempt to parse and validate the response as a StudentProfile\n",
    "        student_profile = StudentProfile.parse_raw(response)\n",
    "        return student_profile\n",
    "    except ValidationError as e:\n",
    "        # Catch invalid JSON or schema errors and return None\n",
    "        print(f\"Invalid JSON or structure: {e}\")\n",
    "        return None\n",
    "    except json.JSONDecodeError as e:\n",
    "        # Catch invalid JSON formatting errors\n",
    "        print(f\"JSON Decode Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = \"\"\"<|im_start|>system\n",
    "You are a helpful assistant that answers in JSON. Follow the exact JSON schema below:\n",
    "<schema>\n",
    "{{\n",
    "    \"major\": \"string\",\n",
    "    \"bio\": \"string\"\n",
    "}}\n",
    "</schema>\n",
    "When writing the \"bio\", strictly adhere to these rules:\n",
    "1. Only include the student's experiences, activities, achievements, projects, leadership positions, internships, research, and career goals.\n",
    "2. Do NOT include any personal information such as the student's name, gender, school name, hometown, ethnicity, or other identifiable details.\n",
    "3. Write the bio in 3-6 sentences, focusing on the professional and academic highlights of the student, using concise and formal language.\n",
    "<|im_end|>\n",
    "<|im_start|>user\n",
    "Generate a college student profile for a {major} major. Write a \"bio\" that is detailed but does not include any personal identifiers, and only focuses on the student's academic and professional experiences, activities, and goals. <|im_end|>\n",
    "<|im_start|>assistant\n",
    "\"\"\"\n",
    "\n",
    "major = \"Computer Science\"\n",
    "formatted_prompt = chat_template.format(major=major)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant that answers in JSON. Here's the json schema you must adhere to:\n",
      "<schema>\n",
      "{\n",
      "    \"major\": \"string\",\n",
      "    \"bio\": \"string\"\n",
      "}\n",
      "</schema><|im_end|>\n",
      "<|im_start|>user\n",
      "Generate a college student profile for Computer Science major. For the bio, in 3-6 sentences write a detailed description of the student's activities, achievements, projects, leadership positions, internships, research, and goals.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(model, tokenizer, prompt, temperature=1.0, num_return_sequences=1, device = \"cuda\")->json:\n",
    "    \"\"\"\n",
    "    Generate a response from the model given a prompt. Runs 4 times before failing and returning None.\n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(4):\n",
    "\n",
    "        try:\n",
    "            input_ids = tokenizer(prompt, padding=True, return_tensors=\"pt\").input_ids.to(device)\n",
    "\n",
    "            # Generate\n",
    "            generated_ids = model.generate(\n",
    "                input_ids,\n",
    "                temperature=temperature, \n",
    "                repetition_penalty=1.1,\n",
    "                num_return_sequences=num_return_sequences,\n",
    "                do_sample=True, \n",
    "                max_length=512,\n",
    "                eos_token_id=tokenizer.eos_token_id\n",
    "            )\n",
    "            \n",
    "            # Decode and return the generated text\n",
    "            response = tokenizer.decode(generated_ids[0][input_ids.shape[-1]:], skip_special_tokens=True, clean_up_tokenization_space=True)\n",
    "            json_response = json.loads(response)\n",
    "            return json_response\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Attempt {i+1} failed with: {e}\")\n",
    "            print(response)\n",
    "            if i == 3:\n",
    "                return None\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'major': 'Computer Science',\n",
       " 'bio': 'A dedicated student with a keen interest in computer science, this individual has consistently demonstrated strong analytical skills and a passion for innovation. Through various programming projects and coursework, they have honed their proficiency in languages such as Python, Java, and C++. Their involvement in hackathons and coding competitions has not only sharpened their problem-solving abilities but also exposed them to collaborative teamwork. With aspirations towards contributing meaningful solutions in the tech industry, this student seeks to further develop their expertise in areas like artificial intelligence and cybersecurity. They believe that continuous learning and real-world experience will be instrumental in achieving their goal of making a significant impact in the field.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_response(model, tokenizer, formatted_prompt, temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "majors = {\n",
    "    \"STEM\": [\n",
    "        \"Computer Science\",\n",
    "        \"Mechanical Engineering\",\n",
    "        \"Biology\",\n",
    "        \"Physics\",\n",
    "    ],\n",
    "    \"Arts\": [\n",
    "        \"Graphic Design\",\n",
    "        \"Music\",\n",
    "        \"Theater\",\n",
    "    ],\n",
    "    \"Business\": [\n",
    "        \"Business Administration\",\n",
    "        \"Finance\",\n",
    "        \"Marketing\",\n",
    "        # \"Accounting\",\n",
    "        # \"Economics\"\n",
    "    ],\n",
    "    \"Humanities\": [\n",
    "        \"Psychology\",\n",
    "        # \"Sociology\",\n",
    "        # \"Philosophy\",\n",
    "        # \"Political Science\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = []\n",
    "for field, majors in majors.items():\n",
    "\n",
    "    for major in majors:\n",
    "        formatted_prompt = chat_template.format(major=major)\n",
    "        response = generate_response(model, tokenizer, formatted_prompt, temperature=0.5)\n",
    "        if response:\n",
    "            data.append({\"field\": field, \"major\": major, \"bio\": response[\"bio\"]})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field</th>\n",
       "      <th>major</th>\n",
       "      <th>bio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STEM</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>A dedicated student with a passion for technol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>STEM</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>A dedicated student with a passion for innovat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STEM</td>\n",
       "      <td>Biology</td>\n",
       "      <td>A dedicated and curious student, the Biology m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>STEM</td>\n",
       "      <td>Physics</td>\n",
       "      <td>A dedicated and curious learner, the Physics m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arts</td>\n",
       "      <td>Graphic Design</td>\n",
       "      <td>A dedicated and creative individual with a pas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  field                   major  \\\n",
       "0  STEM        Computer Science   \n",
       "1  STEM  Mechanical Engineering   \n",
       "2  STEM                 Biology   \n",
       "3  STEM                 Physics   \n",
       "4  Arts          Graphic Design   \n",
       "\n",
       "                                                 bio  \n",
       "0  A dedicated student with a passion for technol...  \n",
       "1  A dedicated student with a passion for innovat...  \n",
       "2  A dedicated and curious student, the Biology m...  \n",
       "3  A dedicated and curious learner, the Physics m...  \n",
       "4  A dedicated and creative individual with a pas...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the df\n",
    "df.to_csv(\"student_profiles.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
